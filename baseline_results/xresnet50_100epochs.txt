/home/gobind/.fastai/data/cifar10
epoch     train_loss  valid_loss  accuracy  time    
0         38.386906   #na#        00:05     
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Min numerical gradient: 1.20E-03
Min loss divided by 10: 3.02E-02
epoch     train_loss  valid_loss  accuracy  time    
0         1.518467    1.454644    0.475900  00:20     
1         1.350118    1.304636    0.529300  00:20     
2         1.288139    1.225098    0.565200  00:20     
3         1.191859    1.147470    0.588600  00:20     
4         1.127506    1.105662    0.606000  00:20     
5         1.075631    1.049913    0.626000  00:20     
6         1.020326    0.989322    0.648800  00:20     
7         0.977261    0.957672    0.669400  00:20     
8         0.943691    0.928038    0.671300  00:20     
9         0.883036    0.913189    0.681700  00:21     
10        0.861817    0.910606    0.685800  00:20     
11        0.798465    0.760672    0.735000  00:21     
12        0.762884    0.762033    0.736900  00:20     
13        0.740995    0.786655    0.731600  00:21     
14        0.700460    0.750800    0.742600  00:21     
15        0.675003    0.721896    0.747400  00:20     
16        0.620387    0.692609    0.767300  00:21     
17        0.619445    0.672948    0.771500  00:21     
18        0.587505    0.588817    0.799000  00:21     
19        0.553398    0.694478    0.774400  00:21     
20        0.527389    0.664100    0.779300  00:20     
21        0.492145    0.613407    0.798600  00:21     
22        0.469439    0.597620    0.803700  00:21     
23        0.448782    0.577213    0.809900  00:21     
24        0.433697    0.613225    0.795600  00:21     
25        0.413630    0.557343    0.820800  00:20     
26        0.388698    0.540394    0.828700  00:21     
27        0.380107    0.547291    0.823200  00:21     
28        0.350511    0.505246    0.841100  00:20     
29        0.333615    0.542685    0.828000  00:21     
30        0.321071    0.476562    0.852100  00:21     
31        0.296494    0.516730    0.842600  00:21     
32        0.287983    0.490656    0.844900  00:21     
33        0.274040    0.518286    0.844900  00:21     
34        0.251267    0.546216    0.838500  00:21     
35        0.236043    0.543133    0.846900  00:20     
36        0.217498    0.500373    0.853500  00:21     
37        0.221332    0.503719    0.856100  00:21     
38        0.202179    0.552589    0.850400  00:21     
39        0.197431    0.522047    0.854900  00:21     
40        0.179236    0.518383    0.860100  00:21     
41        0.170910    0.516624    0.858900  00:21     
42        0.163115    0.542110    0.852400  00:21     
43        0.146751    0.577832    0.853900  00:21     
44        0.149902    0.539310    0.856600  00:21     
45        0.147573    0.546239    0.856900  00:21     
46        0.130728    0.536911    0.866300  00:21     
47        0.125000    0.517283    0.865000  00:20     
48        0.127478    0.536680    0.859100  00:21     
49        0.110986    0.516086    0.868700  00:20     
50        0.101198    0.541570    0.867100  00:21     
51        0.100951    0.536703    0.869300  00:21     
52        0.089166    0.542912    0.870900  00:21     
53        0.092377    0.545602    0.868900  00:20     
54        0.080488    0.528346    0.868900  00:21     
55        0.080488    0.576811    0.861200  00:21     
56        0.077532    0.525726    0.875900  00:21     
57        0.068465    0.570440    0.870500  00:21     
58        0.068875    0.587892    0.868300  00:21     
59        0.057679    0.545430    0.876000  00:21     
60        0.053658    0.571446    0.873200  00:20     
61        0.051005    0.550032    0.878000  00:21     
62        0.045005    0.565934    0.872900  00:21     
63        0.046250    0.542002    0.879000  00:21     
64        0.043220    0.571611    0.875300  00:21     
65        0.040136    0.556843    0.880800  00:21     
66        0.035194    0.562971    0.878700  00:21     
67        0.031100    0.574060    0.878800  00:21     
68        0.035338    0.575395    0.882300  00:21     
69        0.026655    0.574863    0.884200  00:21     
70        0.024031    0.564474    0.883100  00:21     
71        0.021356    0.573357    0.882100  00:21     
72        0.022919    0.576087    0.882000  00:21     
73        0.018385    0.582143    0.882700  00:21     
74        0.018550    0.573505    0.883800  00:21     
75        0.017740    0.586921    0.886200  00:21     
76        0.014709    0.593942    0.886000  00:21     
77        0.015101    0.578999    0.885400  00:21     
78        0.012532    0.581485    0.890600  00:21     
79        0.011820    0.578789    0.890000  00:21     
80        0.011211    0.573414    0.891500  00:21     
81        0.008279    0.589883    0.891100  00:21     
82        0.008101    0.601685    0.890900  00:21     
83        0.007830    0.597000    0.887000  00:21     
84        0.006876    0.603817    0.889300  00:21     
85        0.008051    0.601734    0.888600  00:21     
86        0.006615    0.596093    0.892300  00:21     
87        0.004826    0.587685    0.893300  00:21     
88        0.005456    0.580593    0.894000  00:21     
89        0.005095    0.591533    0.892900  00:21     
90        0.003847    0.591006    0.894300  00:21     
91        0.003925    0.591848    0.895500  00:21     
92        0.004606    0.591575    0.896200  00:21     
93        0.003622    0.588455    0.895400  00:21     
94        0.003351    0.582821    0.895500  00:21     
95        0.003249    0.584094    0.896200  00:21     
96        0.002686    0.584981    0.896800  00:21     
97        0.003309    0.588237    0.895300  00:21     
98        0.003109    0.588147    0.895300  00:21     
99        0.003316    0.592196    0.895900  00:21     
