/home/gobind/.fastai/data/cifar10
epoch     train_loss  valid_loss  accuracy  time    
0         19.576260   #na#        00:04     
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Min numerical gradient: 3.63E-03
Min loss divided by 10: 9.12E-02
epoch     train_loss  valid_loss  accuracy  time    
0         1.476907    1.360420    0.507700  00:15     
1         1.239511    1.187443    0.574300  00:15     
2         1.122446    1.075250    0.615400  00:15     
3         1.034885    1.094837    0.625400  00:16     
4         0.949589    0.950140    0.664500  00:15     
5         0.872122    0.952398    0.666600  00:15     
6         0.803035    0.852339    0.707400  00:16     
7         0.755412    0.722289    0.745500  00:15     
8         0.711615    0.715078    0.751200  00:15     
9         0.674748    0.688822    0.761200  00:15     
10        0.625869    0.707025    0.761800  00:16     
11        0.584685    0.606964    0.790400  00:15     
12        0.570699    0.671366    0.772800  00:16     
13        0.532632    0.680503    0.773400  00:16     
14        0.512957    0.560813    0.808600  00:16     
15        0.479808    0.578350    0.807000  00:16     
16        0.452941    0.577096    0.806900  00:16     
17        0.422087    0.581498    0.806100  00:15     
18        0.402926    0.519456    0.826500  00:16     
19        0.380839    0.619335    0.803200  00:16     
20        0.365643    0.572078    0.811500  00:16     
21        0.344220    0.498511    0.839300  00:16     
22        0.320929    0.504421    0.833900  00:15     
23        0.308188    0.537419    0.836800  00:15     
24        0.294561    0.470850    0.853500  00:16     
25        0.278637    0.600286    0.829200  00:15     
26        0.261149    0.513282    0.847900  00:16     
27        0.239642    0.485122    0.855100  00:16     
28        0.223132    0.475605    0.859700  00:15     
29        0.212549    0.501555    0.848900  00:15     
30        0.205241    0.470932    0.863900  00:15     
31        0.193952    0.447387    0.868800  00:16     
32        0.171876    0.450842    0.876200  00:15     
33        0.150746    0.449451    0.876100  00:16     
34        0.152486    0.474277    0.871300  00:16     
35        0.123322    0.454165    0.880400  00:16     
36        0.124368    0.463483    0.878100  00:16     
37        0.102644    0.440622    0.884100  00:16     
38        0.090122    0.452677    0.886900  00:16     
39        0.077518    0.460020    0.886000  00:16     
40        0.066516    0.461617    0.889500  00:16     
41        0.065520    0.467943    0.889100  00:16     
42        0.062012    0.468615    0.891000  00:16     
43        0.055694    0.456747    0.893200  00:16     
44        0.048858    0.455829    0.892900  00:15     
45        0.046896    0.462748    0.894600  00:16     
46        0.042099    0.465935    0.893700  00:16     
47        0.043102    0.465678    0.894800  00:16     
48        0.043564    0.466216    0.895700  00:16     
49        0.047136    0.463927    0.895500  00:16     
