/home/gobind/.fastai/data/cifar10
epoch     train_loss  valid_loss  accuracy  time    
0         22.971441   #na#        00:03     
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Min numerical gradient: 4.37E-03
Min loss divided by 10: 7.59E-02
epoch     train_loss  valid_loss  accuracy  time    
0         1.451654    1.369939    0.504500  00:10     
1         1.249061    1.167937    0.578700  00:10     
2         1.141117    1.070435    0.615100  00:10     
3         1.047488    0.979771    0.651500  00:11     
4         0.969305    0.961617    0.669600  00:11     
5         0.929272    0.911030    0.681100  00:11     
6         0.863465    0.834897    0.705300  00:11     
7         0.824574    0.784410    0.727800  00:11     
8         0.794194    0.748100    0.737100  00:11     
9         0.741958    0.743401    0.747700  00:11     
10        0.707397    0.792994    0.729100  00:11     
11        0.677709    0.697943    0.764900  00:11     
12        0.649165    0.707389    0.755300  00:11     
13        0.624052    0.658503    0.775200  00:11     
14        0.600589    0.654469    0.780900  00:11     
15        0.569202    0.659554    0.778600  00:11     
16        0.543087    0.672099    0.773000  00:11     
17        0.524946    0.595813    0.796500  00:11     
18        0.511675    0.551859    0.810700  00:11     
19        0.494194    0.572639    0.808300  00:11     
20        0.473340    0.600475    0.805900  00:11     
21        0.470074    0.646763    0.788600  00:11     
22        0.457082    0.575059    0.814700  00:11     
23        0.443067    0.568004    0.809900  00:11     
24        0.426445    0.585291    0.810200  00:11     
25        0.393644    0.484954    0.842100  00:11     
26        0.393913    0.520433    0.830800  00:11     
27        0.398051    0.500498    0.835600  00:11     
28        0.369287    0.470091    0.840000  00:11     
29        0.370746    0.529672    0.828900  00:11     
30        0.347908    0.502009    0.842900  00:11     
31        0.344350    0.484107    0.842700  00:11     
32        0.315519    0.479535    0.847400  00:11     
33        0.321835    0.466721    0.851600  00:11     
34        0.309733    0.502225    0.842300  00:11     
35        0.299993    0.472323    0.855900  00:11     
36        0.294314    0.476261    0.848900  00:11     
37        0.292240    0.472330    0.854000  00:11     
38        0.281357    0.467882    0.855500  00:11     
39        0.257778    0.472899    0.858600  00:11     
40        0.267849    0.461136    0.859200  00:11     
41        0.241839    0.484059    0.856500  00:11     
42        0.247503    0.437411    0.863100  00:11     
43        0.233284    0.476497    0.857300  00:11     
44        0.219705    0.502955    0.853900  00:11     
45        0.231586    0.507183    0.852500  00:11     
46        0.209700    0.475558    0.866400  00:11     
47        0.207250    0.455696    0.864900  00:11     
48        0.197917    0.453082    0.869600  00:11     
49        0.198238    0.473087    0.864300  00:11     
50        0.196245    0.508260    0.854700  00:11     
51        0.183999    0.453968    0.874000  00:11     
52        0.172856    0.458300    0.870000  00:11     
53        0.166294    0.462480    0.867500  00:11     
54        0.165687    0.472522    0.869300  00:11     
55        0.152931    0.471284    0.867600  00:11     
56        0.137440    0.464681    0.874500  00:11     
57        0.139169    0.471038    0.876000  00:11     
58        0.135937    0.449821    0.876700  00:11     
59        0.126605    0.490409    0.871300  00:11     
60        0.132114    0.481737    0.875000  00:11     
61        0.114933    0.474822    0.875000  00:11     
62        0.113742    0.475297    0.876000  00:11     
63        0.109449    0.469136    0.881800  00:11     
64        0.100026    0.467024    0.878400  00:11     
65        0.094578    0.478319    0.880800  00:11     
66        0.097295    0.492531    0.879800  00:11     
67        0.085396    0.492573    0.879200  00:11     
68        0.079202    0.509896    0.879900  00:11     
69        0.073259    0.495262    0.884400  00:11     
70        0.066577    0.501977    0.883800  00:11     
71        0.065027    0.504966    0.884800  00:11     
72        0.063458    0.498149    0.886000  00:11     
73        0.056261    0.511759    0.889000  00:11     
74        0.052948    0.506059    0.888400  00:11     
75        0.052769    0.520252    0.891000  00:11     
76        0.052691    0.505636    0.890700  00:11     
77        0.044133    0.514035    0.892900  00:11     
78        0.038130    0.515672    0.891900  00:11     
79        0.036058    0.513183    0.892200  00:11     
80        0.037227    0.512052    0.893600  00:11     
81        0.034735    0.520465    0.891900  00:11     
82        0.026117    0.521160    0.891700  00:11     
83        0.030850    0.534962    0.893700  00:11     
84        0.023761    0.543580    0.892300  00:11     
85        0.021599    0.540922    0.893700  00:11     
86        0.020251    0.550571    0.896900  00:11     
87        0.020602    0.551908    0.895600  00:11     
88        0.022355    0.537412    0.897100  00:11     
89        0.015979    0.540054    0.897200  00:11     
90        0.015570    0.543967    0.897600  00:11     
91        0.012972    0.538655    0.898200  00:11     
92        0.018106    0.540314    0.897200  00:11     
93        0.014103    0.543938    0.897200  00:11     
94        0.012301    0.541380    0.896100  00:11     
95        0.012484    0.547715    0.896500  00:11     
96        0.012057    0.545750    0.897100  00:11     
97        0.011628    0.542858    0.898500  00:11     
98        0.011674    0.547334    0.897800  00:11     
99        0.012760    0.551804    0.898700  00:11     
