epoch     train_loss  valid_loss  accuracy  time    
0         9.595454    #na#        00:02     
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Min numerical gradient: 1.20E-03
Min loss divided by 10: 1.91E-03
epoch     train_loss  valid_loss  accuracy  time    
/home/gobind/miniconda3/lib/python3.7/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel warn("You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel")
0         1.401320    1.435759    0.479600  00:09     
1         1.173615    1.314893    0.547600  00:09     
2         1.026591    1.205991    0.578700  00:09     
3         0.903345    1.176783    0.587200  00:09     
4         0.807897    1.018925    0.646400  00:09     
5         0.683544    1.089947    0.643000  00:09     
6         0.563752    1.163908    0.641400  00:09     
7         0.462714    1.211233    0.640900  00:09     
8         0.384565    1.360821    0.646300  00:09     
9         0.316412    1.484901    0.632000  00:09     
10        0.259456    1.568494    0.638600  00:09     
11        0.222192    1.709512    0.634400  00:09     
12        0.202786    1.726357    0.631900  00:09     
13        0.175311    1.709911    0.638100  00:09     
14        0.159515    1.820525    0.642700  00:09     
15        0.145526    1.825541    0.649500  00:09     
16        0.135541    1.835933    0.645900  00:09     
17        0.124996    1.954466    0.634800  00:09     
18        0.123679    1.919483    0.645800  00:09     
19        0.108775    2.027560    0.638300  00:09     
20        0.095747    2.110475    0.639500  00:09     
21        0.108428    2.054230    0.640500  00:09     
22        0.104476    2.044964    0.642900  00:09     
23        0.092655    2.123136    0.634600  00:09     
24        0.083597    2.152406    0.644500  00:09     
25        0.078930    2.192473    0.643700  00:09     
26        0.074014    2.100753    0.646300  00:09     
27        0.068698    2.231618    0.648000  00:09     
28        0.073499    2.168229    0.640700  00:09     
29        0.065902    2.194508    0.649700  00:09     
