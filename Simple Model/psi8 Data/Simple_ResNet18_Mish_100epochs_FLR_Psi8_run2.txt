epoch     train_loss  valid_loss  accuracy  time    
0         10.913715   #na#        00:04     
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Min numerical gradient: 5.75E-04
Min loss divided by 10: 1.91E-03
epoch     train_loss  valid_loss  accuracy  time    
/home/gobind/miniconda3/lib/python3.7/site-packages/fastai/sixel.py:16: UserWarning: You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel warn("You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel")
0         1.413337    1.444217    0.482100  00:17     
1         1.207985    1.263627    0.552600  00:17     
2         1.030361    1.163876    0.592800  00:18     
3         0.888252    1.160133    0.598900  00:17     
4         0.755577    1.127342    0.621300  00:17     
5         0.610859    1.191411    0.615700  00:17     
6         0.487198    1.266716    0.621300  00:17     
7         0.397689    1.417973    0.609300  00:14     
8         0.321335    1.631952    0.595100  00:16     
9         0.278576    1.599374    0.608600  00:18     
10        0.237058    1.737528    0.610900  00:17     
11        0.209949    1.756682    0.614100  00:17     
12        0.194407    1.815806    0.606900  00:17     
13        0.173204    1.906221    0.607400  00:18     
14        0.165416    1.976103    0.616200  00:17     
15        0.150655    1.930610    0.616900  00:18     
16        0.139361    1.978089    0.614500  00:17     
17        0.130327    2.086037    0.619000  00:17     
18        0.112154    2.066628    0.615900  00:17     
19        0.124495    2.060056    0.616900  00:17     
20        0.110980    2.037238    0.617500  00:17     
21        0.097080    2.165721    0.617600  00:18     
22        0.098917    2.163273    0.617600  00:17     
23        0.099255    2.107868    0.625800  00:18     
24        0.092221    2.191660    0.620600  00:17     
25        0.088840    2.242742    0.615700  00:17     
26        0.098690    2.234218    0.624800  00:18     
27        0.085820    2.308020    0.617900  00:17     
28        0.077594    2.278495    0.624200  00:17     
29        0.083993    2.330086    0.625000  00:17     
30        0.070860    2.385449    0.623900  00:17     
31        0.072747    2.412407    0.620600  00:17     
32        0.066487    2.345480    0.622400  00:17     
33        0.073333    2.349088    0.627200  00:17     
34        0.067724    2.417840    0.631800  00:17     
35        0.064028    2.318669    0.626100  00:17     
36        0.057674    2.455705    0.619800  00:17     
37        0.063072    2.502140    0.619100  00:18     
38        0.062700    2.445595    0.626700  00:17     
39        0.065610    2.379164    0.627700  00:18     
40        0.061242    2.354579    0.620400  00:17     
41        0.053187    2.411284    0.628500  00:17     
42        0.049359    2.551988    0.616100  00:18     
43        0.047767    2.576432    0.621000  00:17     
44        0.060351    2.481589    0.626000  00:17     
45        0.050093    2.521617    0.626900  00:17     
46        0.057801    2.502201    0.627000  00:17     
47        0.052115    2.553123    0.622900  00:17     
48        0.038450    2.529734    0.625900  00:18     
49        0.048921    2.586658    0.623500  00:17     
50        0.047586    2.480597    0.627300  00:17     
51        0.045189    2.577688    0.628500  00:17     
52        0.041818    2.545029    0.629800  00:18     
53        0.040787    2.572561    0.630100  00:17     
54        0.043476    2.598577    0.619000  00:17     
55        0.038302    2.518239    0.636200  00:17     
56        0.038598    2.663862    0.630500  00:17     
57        0.044302    2.581089    0.630100  00:18     
58        0.034798    2.537744    0.632600  00:17     
59        0.041634    2.615072    0.622800  00:17     
60        0.039922    2.746901    0.623400  00:17     
61        0.038841    2.621934    0.630600  00:17     
62        0.035764    2.717969    0.626900  00:17     
63        0.038217    2.650079    0.631200  00:17     
64        0.030704    2.686099    0.623500  00:18     
65        0.033291    2.580140    0.631200  00:17     
66        0.035939    2.731892    0.623600  00:17     
67        0.033162    2.769945    0.625000  00:18     
68        0.038139    2.725396    0.621000  00:18     
69        0.032758    2.720562    0.629600  00:17     
70        0.040772    2.671217    0.624800  00:17     
71        0.033354    2.784532    0.627100  00:18     
72        0.031932    2.726626    0.634800  00:17     
73        0.033326    2.778528    0.623500  00:17     
74        0.024576    2.802746    0.630300  00:17     
75        0.034603    2.711750    0.628700  00:17     
76        0.028004    2.722160    0.634700  00:17     
77        0.025718    2.750760    0.634100  00:17     
78        0.027427    2.839054    0.626200  00:17     
79        0.034240    2.849607    0.627000  00:17     
80        0.029353    2.835627    0.634300  00:17     
81        0.029509    2.850400    0.630100  00:17     
82        0.027172    2.766941    0.633600  00:17     
83        0.038201    2.701048    0.635000  00:17     
84        0.030446    2.853662    0.627900  00:17     
85        0.028494    2.833880    0.631100  00:17     
86        0.027304    2.827906    0.634600  00:17     
87        0.027165    2.798043    0.630700  00:17     
88        0.026258    2.936279    0.632600  00:17     
89        0.029114    2.847883    0.634400  00:17     
90        0.032207    2.819134    0.628700  00:17     
91        0.023299    2.876668    0.634300  00:17     
92        0.028207    2.832420    0.626700  00:17     
93        0.026439    2.945349    0.624800  00:17     
94        0.026755    2.781487    0.637700  00:17     
95        0.026351    2.869618    0.628400  00:17     
96        0.020459    2.874791    0.631100  00:17     
97        0.024516    2.850738    0.629900  00:17     
98        0.024628    2.964053    0.627200  00:17     
99        0.028268    2.930977    0.628600  00:17     
